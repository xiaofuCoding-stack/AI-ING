#!/usr/bin/env python3
"""
Project Analyzer - Analyzes open-source technologies and extracts core principles

Usage:
    analyze_project.py --project-dir <dir> --output-dir <dir> [--project <name>]

Examples:
    analyze_project.py --project-dir project/ --output-dir sumup/
    analyze_project.py --project-dir project/ --output-dir sumup/ --project clawdbot
"""

import argparse
import json
import re
import sys
from pathlib import Path
from typing import Dict, List, Optional

def find_projects(project_dir: Path) -> List[Path]:
    """Discover projects in the directory."""
    projects = []
    if not project_dir.exists():
        return projects
    
    # Look for top-level directories with common project indicators
    for item in project_dir.iterdir():
        if item.is_dir() and not item.name.startswith('.'):
            # Check for project indicators
            indicators = ['README.md', 'package.json', 'requirements.txt', 'Cargo.toml', 'go.mod', 'pom.xml']
            if any((item / indicator).exists() for indicator in indicators):
                projects.append(item)
    
    return projects

def extract_project_metadata(project_path: Path) -> Dict:
    """Extract basic metadata from a project."""
    metadata = {
        'name': project_path.name,
        'path': str(project_path),
        'type': 'unknown',
        'description': '',
        'tech_stack': [],
        'has_readme': False,
        'has_docs': False,
    }
    
    # Check for README
    readme_path = project_path / 'README.md'
    if readme_path.exists():
        metadata['has_readme'] = True
        try:
            content = readme_path.read_text(encoding='utf-8', errors='ignore')
            # Extract first paragraph as description
            lines = content.split('\n')
            for line in lines[:20]:  # Check first 20 lines
                line = line.strip()
                if line and not line.startswith('#') and not line.startswith('['):
                    metadata['description'] = line[:200]  # First 200 chars
                    break
        except Exception:
            pass
    
    # Check for package.json (Node.js/TypeScript)
    package_json = project_path / 'package.json'
    if package_json.exists():
        metadata['type'] = 'nodejs'
        try:
            data = json.loads(package_json.read_text())
            if 'dependencies' in data:
                metadata['tech_stack'].extend(list(data['dependencies'].keys())[:10])
            if 'devDependencies' in data:
                metadata['tech_stack'].extend(list(data['devDependencies'].keys())[:5])
        except Exception:
            pass
    
    # Check for requirements.txt (Python)
    requirements = project_path / 'requirements.txt'
    if requirements.exists() and metadata['type'] == 'unknown':
        metadata['type'] = 'python'
    
    # Check for docs directory
    if (project_path / 'docs').exists():
        metadata['has_docs'] = True
    
    return metadata

def generate_analysis_structure(project_metadata: Dict, output_dir: Path):
    """Generate initial analysis document structure."""
    project_name = project_metadata['name']
    safe_name = re.sub(r'[^a-zA-Z0-9-]', '-', project_name.lower())
    
    # Create output directory
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Generate core principles document
    core_principles = output_dir / f"{safe_name}-core-principles.md"
    if not core_principles.exists():
        content = f"""# {project_name} - Core Technical Principles

## Overview

{project_metadata.get('description', 'Project description to be analyzed.')}

**Project Type**: {project_metadata.get('type', 'unknown').upper()}
**Tech Stack**: {', '.join(project_metadata.get('tech_stack', [])[:10]) if project_metadata.get('tech_stack') else 'To be analyzed'}

## Core Design Principles

[To be analyzed - extract fundamental design decisions and architectural patterns]

## Key Abstractions

[To be analyzed - identify main abstractions and interfaces]

## Architectural Patterns

[To be analyzed - identify patterns like gateway, plugin system, etc.]

## Latest Technical Updates

[To be analyzed - review CHANGELOG.md or recent commits]

---
*Generated by tech-analyzer skill. Complete this analysis by reviewing the project source code and documentation.*
"""
        core_principles.write_text(content, encoding='utf-8')
        print(f"[OK] Created {core_principles.name}")
    
    # Generate architecture document
    architecture = output_dir / f"{safe_name}-architecture.md"
    if not architecture.exists():
        content = f"""# {project_name} - Architecture Overview

## System Architecture

[To be analyzed - describe overall system structure]

## Component Overview

[To be analyzed - list and describe main components]

## Data Flow

[To be analyzed - describe how data flows through the system]

## Extension Points

[To be analyzed - how does the system allow extensions/plugins?]

## Communication Patterns

[To be analyzed - how do components communicate?]

---
*Generated by tech-analyzer skill. Complete this analysis by reviewing the project source code and documentation.*
"""
        architecture.write_text(content, encoding='utf-8')
        print(f"[OK] Created {architecture.name}")
    
    # Generate implementation document
    implementation = output_dir / f"{safe_name}-implementation.md"
    if not implementation.exists():
        content = f"""# {project_name} - Implementation Details

## Technology Stack

[To be analyzed - detailed list of technologies, frameworks, libraries]

## Key Dependencies

{chr(10).join(f'- {dep}' for dep in project_metadata.get('tech_stack', [])[:20]) if project_metadata.get('tech_stack') else '[To be analyzed]'}

## Implementation Patterns

[To be analyzed - coding patterns, design patterns used]

## Build and Deployment

[To be analyzed - how is the project built and deployed?]

## Configuration

[To be analyzed - configuration mechanisms and options]

---
*Generated by tech-analyzer skill. Complete this analysis by reviewing the project source code and documentation.*
"""
        implementation.write_text(content, encoding='utf-8')
        print(f"[OK] Created {implementation.name}")

def analyze_project(project_dir: Path, output_dir: Path, project_name: Optional[str] = None):
    """Main analysis function."""
    print(f"Analyzing projects in: {project_dir}")
    print(f"Output directory: {output_dir}\n")
    
    if project_name:
        # Analyze specific project
        project_path = project_dir / project_name
        if not project_path.exists():
            print(f"[ERROR] Project not found: {project_path}")
            sys.exit(1)
        projects = [project_path]
    else:
        # Discover all projects
        projects = find_projects(project_dir)
        if not projects:
            print(f"[WARNING] No projects found in {project_dir}")
            return
    
    print(f"Found {len(projects)} project(s):\n")
    
    for project_path in projects:
        print(f"Analyzing: {project_path.name}")
        metadata = extract_project_metadata(project_path)
        print(f"  Type: {metadata['type']}")
        print(f"  Has README: {metadata['has_readme']}")
        print(f"  Has docs: {metadata['has_docs']}")
        if metadata['tech_stack']:
            print(f"  Tech stack: {', '.join(metadata['tech_stack'][:5])}...")
        print()
        
        generate_analysis_structure(metadata, output_dir)
        print()

def main():
    parser = argparse.ArgumentParser(
        description="Analyze open-source technologies and extract core principles"
    )
    parser.add_argument(
        "--project-dir",
        required=True,
        help="Directory containing projects to analyze"
    )
    parser.add_argument(
        "--output-dir",
        required=True,
        help="Output directory for generated documentation"
    )
    parser.add_argument(
        "--project",
        help="Specific project name to analyze (optional, analyzes all if not specified)"
    )
    args = parser.parse_args()
    
    project_dir = Path(args.project_dir).resolve()
    output_dir = Path(args.output_dir).resolve()
    
    if not project_dir.exists():
        print(f"[ERROR] Project directory does not exist: {project_dir}")
        sys.exit(1)
    
    analyze_project(project_dir, output_dir, args.project)

if __name__ == "__main__":
    main()
